#! /usr/bin/env python2
# -*- encoding: utf-8; py-indent-offset: 4 -*-
#
# Author:  Linuxfabrik GmbH, Zurich, Switzerland
# Contact: info (at) linuxfabrik (dot) ch
#          https://www.linuxfabrik.ch/
# License: The Unlicense, see LICENSE file.

# https://nagios-plugins.org/doc/guidelines.html

__author__  = 'Linuxfabrik GmbH, Zurich/Switzerland'
__version__ = '2020012501'

DESCRIPTION = 'This program tests connections to a mysql server and gets some statistics.'

DEFAULT_HOSTNAME = '127.0.0.1'
DEFAULT_PORT = '3306'


#====================
from lib.globals import *

import argparse
import mysql.connector

from lib.output import unpack_perfdata, bytes2human
from mysql.connector import errorcode
from psutil import virtual_memory


def define_args():
    parser = argparse.ArgumentParser(description=DESCRIPTION)

    parser.add_argument('--database',
        help = 'Check database with indicated name.',
        dest = 'DATABASE',
        required = True,        
        )

    parser.add_argument('-H', '--hostname',
        help = 'MySQL/MariaDB hostname. Default: %(default)s',
        dest = 'HOSTNAME',
        default = DEFAULT_HOSTNAME,
        )

    parser.add_argument('-p', '--password',
        help = 'Use the indicated password to authenticate the connection. IMPORTANT: THIS FORM OF AUTHENTICATION IS NOT SECURE.',
        dest = 'PASSWORD',
        required = True,        
        )

    parser.add_argument('--port',
        help = 'MySQL/MariaDB port. Default: %(default)s',
        dest = 'PORT',
        default = DEFAULT_PORT,
        )

    parser.add_argument('-u', '--username',
        help = 'MySQL/MariaDB username.',
        dest = 'USERNAME',
        required = True,        
        )

    parser.add_argument('-V', '--version',
        action = 'version',
        version = '{0}: v{1} by {2}'.format('%(prog)s', __version__, __author__)
        )

    return parser.parse_args()


def smartcast(value):
     for test in [int, str]:
         try:
             return test(value)
         except ValueError:
             continue
     # No match
     return value


def get_pf_memory():
    # todo as in https://github.com/major/MySQLTuner-perl/blob/master/mysqltuner.pl
    return 0;


def get_other_process_memory():
    # todo as in https://github.com/major/MySQLTuner-perl/blob/master/mysqltuner.pl
    return 0;


def main():
    # parse the command line, exit with UNKNOWN if it fails
    try:
        parsed = define_args()
    except SystemExit as e:
        exit(STATE_UNKNOWN)


    try:
        cnx = mysql.connector.connect(
            host = parsed.HOSTNAME,
            port = parsed.PORT,
            user = parsed.USERNAME,
            password = parsed.PASSWORD,
            database = parsed.DATABASE,
            use_pure = True,
            )
    except mysql.connector.Error as err:
        if err.errno == errorcode.ER_ACCESS_DENIED_ERROR:
            print('Wrong username or password')
            exit(STATE_UNKNOWN)
        elif err.errno == errorcode.ER_BAD_DB_ERROR:
            print('Unknown database')
            exit(STATE_UNKNOWN)
        else:
            print(err)
            exit(STATE_UNKNOWN)


    myvar = {}
    mystat = {}
    mycalc = {}

    cursor = cnx.cursor()

    query = 'select version();'
    cursor.execute(query)
    version = cursor.fetchone()
    if len(version) <1:
        print('You probably did not get enough privileges for running this check.')
        exit(STATE_UNKNOWN)
    
    version = version[0].split('.')
    mysqlvermajor = int(version[0])
    mysqlverminor = int(version[1])
    mysqlvermicro = version[2]
    mysqltype = 'mariadb' if 'MariaDB' in mysqlvermicro else 'mysql'


    # https://dev.mysql.com/doc/refman/8.0/en/show-variables.html
    query = ('show global variables;')
    cursor.execute(query)
    for (key, value) in cursor:
        myvar[key] = smartcast(value)

    # https://dev.mysql.com/doc/refman/8.0/en/show-status.html
    query = ('show global status;')
    cursor.execute(query)
    for (key, value) in cursor:
        mystat[key] = smartcast(value)

    cursor.close()
    cnx.close()

    if len(mystat) <1:
        print('Your server has not answered any queries - cannot continue.')
        exit(STATE_UNKNOWN)



    # calculations as done in mysqltuner.pl
    # https://github.com/major/MySQLTuner-perl/blob/master/mysqltuner.pl
    mem = virtual_memory()
    physical_memory = mem.total

    # Per-thread memory
    if mysqlvermajor >= 4:
        mycalc['per_thread_buffers'] = myvar['read_buffer_size'] + myvar['read_rnd_buffer_size'] + myvar['sort_buffer_size'] + myvar['thread_stack'] + myvar['max_allowed_packet'] + myvar['join_buffer_size']
    else:
        mycalc['per_thread_buffers'] = myvar['record_buffer'] + myvar['record_rnd_buffer'] + myvar['sort_buffer'] + myvar['thread_stack'] + myvar['join_buffer_size']
    mycalc['total_per_thread_buffers'] = mycalc['per_thread_buffers'] * myvar['max_connections']
    mycalc['max_total_per_thread_buffers'] = mycalc['per_thread_buffers'] * mystat['Max_used_connections']

    # Server-wide memory
    mycalc['max_tmp_table_size'] = myvar['max_heap_table_size'] if myvar['tmp_table_size'] > myvar['max_heap_table_size'] else myvar['tmp_table_size']
    mycalc['server_buffers'] = myvar['key_buffer_size'] + mycalc['max_tmp_table_size']
    mycalc['server_buffers'] += myvar['innodb_buffer_pool_size'] if 'innodb_buffer_pool_size' in myvar else 0
    mycalc['server_buffers'] += myvar['innodb_additional_mem_pool_size'] if 'innodb_additional_mem_pool_size' in myvar else 0
    mycalc['server_buffers'] += myvar['innodb_log_buffer_size'] if 'innodb_log_buffer_size' in myvar else 0
    mycalc['server_buffers'] += myvar['query_cache_size'] if 'query_cache_size' in myvar else 0
    mycalc['server_buffers'] += myvar['aria_pagecache_buffer_size'] if 'aria_pagecache_buffer_size' in myvar else 0

    # Global memory
    # Max used memory is memory used by MySQL based on Max_used_connections
    # This is the max memory used theoretically calculated with the max concurrent connection number reached by mysql
    mycalc['max_used_memory'] = mycalc['server_buffers'] + mycalc['max_total_per_thread_buffers'] + get_pf_memory()

    mycalc['pct_max_used_memory'] = int(mycalc['max_used_memory'] / physical_memory * 100)

    # Total possible memory is memory needed by MySQL based on max_connections
    # This is the max memory MySQL can theoretically used if all connections allowed has opened by mysql
    mycalc['max_peak_memory'] = mycalc['server_buffers'] + mycalc['total_per_thread_buffers'] + get_pf_memory()

    # +  get_gcache_memory();
    mycalc['pct_max_physical_memory'] = int(mycalc['max_peak_memory'] / physical_memory * 100)

    # Slow queries
    mycalc['pct_slow_queries'] = int(mystat['Slow_queries'] / mystat['Questions'] * 100)

    # Connections
    mycalc['pct_connections_used'] = int(mystat['Max_used_connections'] / myvar['max_connections'] * 100 )
    mycalc['pct_connections_used'] = 100 if mycalc['pct_connections_used'] > 100 else mycalc['pct_connections_used']

    # Aborted Connections
    mycalc['pct_connections_aborted'] = int(mystat['Aborted_connects'] / mystat['Connections'] * 100)
    
    # Query cache
    if mysqltype == 'mysql' and (mysqlvermajor >= 8 and mysqlvermajor <= 10):
        mycalc['query_cache_efficiency'] = 0
    elif mysqlvermajor >= 4:
        mycalc['query_cache_efficiency'] = mystat['Qcache_hits'] / (mystat['Com_select'] + mystat['Qcache_hits']) * 100
        if myvar['query_cache_size']:
            mycalc['pct_query_cache_used'] = 100 - (mystat['Qcache_free_memory'] / myvar['query_cache_size']) * 100
        if mystat['Qcache_lowmem_prunes'] == 0:
            mycalc['query_cache_prunes_per_day'] = 0
        else:
            mycalc['query_cache_prunes_per_day'] = int(mystat['Qcache_lowmem_prunes'] / ( mystat['Uptime'] / 86400 ))

    # Sorting
    mycalc['total_sorts'] = mystat['Sort_scan'] + mystat['Sort_range']
    mycalc['pct_temp_sort_table'] = int(mystat['Sort_merge_passes'] / mycalc['total_sorts'] * 100) if mycalc['total_sorts'] > 0 else 0

    # Joins
    mycalc['joins_without_indexes'] = mystat['Select_range_check'] + mystat['Select_full_join']
    mycalc['joins_without_indexes_per_day'] = int(mycalc['joins_without_indexes'] / (mystat['Uptime'] / 86400))

    # Temporary tables
    mycalc['pct_temp_disk'] = 0
    if mystat['Created_tmp_tables'] > 0:
        if mystat['Created_tmp_disk_tables'] > 0:
            mycalc['pct_temp_disk'] = int(mystat['Created_tmp_disk_tables'] / mystat['Created_tmp_tables'] * 100)

    # Open files
    mycalc['pct_files_open'] = int(mystat['Open_files'] / myvar['open_files_limit'] * 100) if myvar['open_files_limit'] > 0 else 0

    # Other
    mycalc['pct_connections_aborted'] = int(mystat['Aborted_connects'] / mystat['Connections']) * 100 if mystat['Connections'] > 0 else 0





    msg = ''
    msg_warn = 'WARN: '
    perfdata = ''
    state = STATE_OK




    # checks as done in mysqltuner

    # Memory usage
    if mycalc['pct_max_used_memory'] > 85:
        msg_warn += '* Maximum reached memory usage > 85%\n'
        state = get_greater_state(state, STATE_WARN)
    msg += '* Maximum reached memory usage: {} ({}% of installed RAM)\n'.format(bytes2human(mycalc['max_used_memory']), mycalc['pct_max_used_memory'])
    perfdata += unpack_perfdata('pct_max_used_memory', mycalc['pct_max_used_memory'], '%', 85, None, 0, 100)

    if mycalc['pct_max_physical_memory'] > 85:
        msg_warn += '* Maximum possible memory usage > 85% (reduce your overall MySQL memory footprint for system stability)\n'
        state = get_greater_state(state, STATE_WARN)
    msg += '* Maximum possible memory usage: {} ({}% of installed RAM)\n'.format(bytes2human(mycalc['max_peak_memory']), mycalc['pct_max_physical_memory'])
    perfdata += unpack_perfdata('pct_max_physical_memory', mycalc['pct_max_physical_memory'], '%', 85, None, 0, None)

    if physical_memory < mycalc['max_peak_memory'] + get_other_process_memory():
        msg_warn += '* Overall possible memory usage with other process exceeded memory (dedicate this server to your database for highest performance)\n'
        state = get_greater_state(state, STATE_WARN)

    # Slow queries
    if mycalc['pct_slow_queries'] > 5:
        msg_warn += '* Slow Queries > 5% (use the slow query log to troubleshoot bad queries)\n'
        state = get_greater_state(state, STATE_WARN)
    msg += '* Slow queries: {}% ({}/{})\n'.format(mycalc['pct_slow_queries'], mystat['Slow_queries'], mystat['Questions'])
    perfdata += unpack_perfdata('pct_slow_queries', mycalc['pct_slow_queries'], '%', 5, None, 0, 100)

    # Connections
    if mycalc['pct_connections_used'] > 85:
        msg_warn += '* Connections used > 85% (reduce or eliminate persistent connections to reduce connection usage, increase max_connections, decrease wait_timeout, decrease interactive_timeout)\n'
        state = get_greater_state(state, STATE_WARN)
    msg += '* Highest connection usage: {}% ({}/{})\n'.format(mycalc['pct_connections_used'], mystat['Max_used_connections'], myvar['max_connections'])
    perfdata += unpack_perfdata('pct_connections_used', mycalc['pct_connections_used'], '%', 85, None, 0, 100)

    # Aborted Connections
    if mycalc['pct_connections_aborted'] > 3:
        msg_warn += '* Connectiona aborted > 3% (reduce or eliminate unclosed connections and network issues)\n'
        state = get_greater_state(state, STATE_WARN)
    msg += '* Aborted connections: {}% ({}/{})\n'.format(mycalc['pct_connections_aborted'], mystat['Aborted_connects'], mystat['Connections'])
    perfdata += unpack_perfdata('pct_connections_aborted', mycalc['pct_connections_aborted'], '%', 85, None, 0, 100)

    # name resolution
    if 'skip_networking' in myvar and myvar['skip_networking'] == 'OFF':
        if 'skip_name_resolve' in myvar and myvar['skip_name_resolve'] == 'OFF':
            msg_warn += '* Name resolution is active: a reverse name resolution is made for each new connection and can reduce performance (configure your accounts with ip or subnets only, then update your configuration with skip-name-resolve=1)\n'
            state = get_greater_state(state, STATE_WARN)

    # Query cache
    if mysqlvermajor < 4 or (mysqlvermajor >= 8 and mysqltype == 'mysql'):
        # MySQL versions < 4.01 don't support query caching
        # Query cache have been removed in MySQL 8"
        tmp = 'do nothing'
    elif myvar['query_cache_size'] < 1 and myvar['query_cache_type'] == 'OFF':
        # Query cache is disabled by default due to mutex contention on multiprocessor machines.
        tmp = 'do nothing'
    elif mystat['Com_select'] == 0:
        msg_warn += '* Query cache cannot be analyzed - no SELECT statements executed\n'
        state = get_greater_state(state, STATE_WARN)
    else:
        msg_warn += '* Query cache may be disabled by default due to mutex contention (set query_cache_size=0, query_cache_type=0)\n'
        state = get_greater_state(state, STATE_WARN)
        if mycalc['query_cache_efficiency'] < 20:
            msg_warn += '* Query cache efficiency < 20% (increase query_cache_limit or use smaller result sets)\n'
            state = get_greater_state(state, STATE_WARN)
        msg += '* Query cache efficiency: {}% ({} cached / {} selects)\n'.format(mycalc['query_cache_efficiency'], mystat['Qcache_hits'], mystat['Qcache_hits'] + mystat['Com_select'])
        perfdata += unpack_perfdata('query_cache_efficiency', mycalc['query_cache_efficiency'], '%', '20:', None, 0, 100)
            
        if mycalc['query_cache_prunes_per_day'] > 98:
            if myvar['query_cache_size'] >= 128 * 1024 * 1024:
                msg_warn += '* Increasing the query_cache size over 128M may reduce performance\n'
            else:
                msg_warn += '* Increase query_cache_size up to 128M\n'
            state = get_greater_state(state, STATE_WARN)
        msg += '* Query cache prunes per day: {}\n'.format(mycalc['query_cache_prunes_per_day'])
        perfdata += unpack_perfdata('query_cache_prunes_per_day', mycalc['query_cache_prunes_per_day'], None, 98, None, 0, None)

    # Sorting
    if mycalc['total_sorts'] == 0:
        # No Sort requiring temporary tables
        tmp = 'do nothing'
    else:
        if mycalc['pct_temp_sort_table'] > 10:
            msg_warn += '* Sorts are requiring temporary tables (increase sort_buffer_size, increase read_rnd_buffer_size)\n'
            state = get_greater_state(state, STATE_WARN)
        msg += '* Sorts requiring temporary tables: {}% ({} temp sorts / {} sorts)\n'.format(mycalc['pct_temp_sort_table'], mystat['Sort_merge_passes'], mycalc['total_sorts'])
        perfdata += unpack_perfdata('pct_temp_sort_table', mycalc['pct_temp_sort_table'], '%', 10, None, 0, 100)

    # Joins
    if mycalc['joins_without_indexes_per_day'] > 250:
        msg_warn += '* More than 250 JOINs without indexes per day (increase join_buffer_size until JOINs not using indexes are found, or always use indexes with JOINs)\n'
        state = get_greater_state(state, STATE_WARN)
    msg += '* Joins performed without indexes per day: {}\n'.format(mycalc['joins_without_indexes_per_day'])
    perfdata += unpack_perfdata('joins_without_indexes_per_day', mycalc['joins_without_indexes_per_day'], None, 250, None, 0, None)

    # Temporary tables
    if mystat['Created_tmp_tables'] > 0:
        if mycalc['pct_temp_disk'] > 25 and mycalc['max_tmp_table_size'] < 256 * 1024 * 1024:
            msg_warn += '* Reduce your SELECT DISTINCT queries without LIMIT clause (and/or increase tmp_table_size, increase max_heap_table_size - when making adjustments, make tmp_table_size/max_heap_table_size equal)\n' 
            state = get_greater_state(state, STATE_WARN)
        elif mycalc['pct_temp_disk'] > 25 and mycalc['max_tmp_table_size'] >= 256 * 1024 * 1024:
            msg_warn += '* Reduce your SELECT DISTINCT queries without LIMIT clause, and reduce result set size (temporary table size is already large)\n' 
            state = get_greater_state(state, STATE_WARN)
    msg += '* Temporary tables created on disk: {}% ({} on disk / {} total)\n'.format(mycalc['pct_temp_disk'], mystat['Created_tmp_disk_tables'], mystat['Created_tmp_tables'])
    perfdata += unpack_perfdata('pct_temp_disk', mycalc['pct_temp_disk'], '%', None, None, 0, 100)


    if 'pct_files_open' in mycalc and mycalc['pct_files_open'] > 85:
        msg_warn += '* Open files > 85% (adjust open_files_limit)\n'
        state = get_greater_state(state, STATE_WARN)

    msg += '* Open file limit used: {}% ({}/{})\n'.format(mycalc['pct_files_open'], mystat['Open_files'], myvar['open_files_limit'])
    perfdata += unpack_perfdata('pct_files_open', mycalc['pct_files_open'], '%', 85, None, 0, 100)

    if msg_warn != 'WARN: ':
        msg = msg_warn.replace('WARN: ', 'There are warnings.\n').strip() + '\n---\n' + msg


    # over and out
    print(msg.strip() + '|' + perfdata.strip())
    exit(state)


if __name__ == '__main__':
    main()
