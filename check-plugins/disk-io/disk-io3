#! /usr/bin/env python3
# -*- encoding: utf-8; py-indent-offset: 4 -*-
#
# Author:  Linuxfabrik GmbH, Zurich, Switzerland
# Contact: info (at) linuxfabrik (dot) ch
#          https://www.linuxfabrik.ch/
# License: The Unlicense, see LICENSE file.

# https://git.linuxfabrik.ch/linuxfabrik-icinga-plugins/checks-linux/-/blob/master/CONTRIBUTING.md

"""Have a look at the check's README for further details.
"""

import os

# considering a virtual environment
ACTIVATE_THIS = False
venv_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'monitoring-plugins-venv3')
if os.path.exists(venv_path):
    ACTIVATE_THIS = os.path.join(venv_path, 'bin/activate_this.py')

if os.getenv('MONITORING_PLUGINS_VENV3'):
    ACTIVATE_THIS = os.path.join(os.getenv('MONITORING_PLUGINS_VENV3') + 'bin/activate_this.py')

if ACTIVATE_THIS and os.path.isfile(ACTIVATE_THIS):
    exec(open(ACTIVATE_THIS).read(), {'__file__': ACTIVATE_THIS}) # pylint: disable=W0122


import argparse # pylint: disable=C0413
import sys # pylint: disable=C0413
from traceback import print_exc # pylint: disable=C0413
try:
    import psutil
except ImportError as e:
    print('Python module "psutil" is not installed.')
    exit(STATE_UNKNOWN)

import lib.base3 # pylint: disable=C0413
import lib.cache3 # pylint: disable=C0413
import lib.db_sqlite3 # pylint: disable=C0413
from lib.globals3 import STATE_OK, STATE_UNKNOWN # pylint: disable=C0413

__author__ = 'Linuxfabrik GmbH, Zurich/Switzerland'
__version__ = '2021051602'

DESCRIPTION = """Checks disk IO."""

DEFAULT_CACHE_EXPIRE = 90
DEFAULT_COUNT = 5       # measurements; if check runs once per minute, this is a 5 minute interval
DEFAULT_WARN = 80       # %
DEFAULT_CRIT = 90       # %
DEFAULT_IGNORE = [
    'sr0',
    'loop0', 'loop1', 'loop2', 'loop3', 'loop4', 'loop5', 'loop6', 'loop7', 'loop8', 'loop9',
    'zram0',
    ]


def parse_args():   
    """Parse command line arguments using argparse.
    """
    parser = argparse.ArgumentParser(description=DESCRIPTION)

    parser.add_argument(
        '-V', '--version',
        action='version',
        version='{0}: v{1} by {2}'.format('%(prog)s', __version__, __author__)
    )

    parser.add_argument(
        '--always-ok',
        help='Always returns OK.',
        dest='ALWAYS_OK',
        action='store_true',
        default=False,
    )

    parser.add_argument(
        '--count',
        help='Number of times the value has to be above the given thresholds. Default: %(default)s',
        dest='COUNT',
        type=int,
        default=DEFAULT_COUNT,
    )

    parser.add_argument(
        '--critical',
        help='Set the CRIT threshold for disk I/O read/write rate over the entire period as a percentage of the maximum disk I/O rate. Default: >= %(default)s',
        dest='CRIT',
        type=int,
        default=DEFAULT_CRIT,
    )

    parser.add_argument(
        '--ignore',
        help='Ignore some disks like "sr0" or "zram0" (repeating). Default: %(default)s',
        dest='IGNORE',
        default=DEFAULT_IGNORE,
        action='append',
    )

    parser.add_argument(
        '--warning',
        help='Set the CRIT threshold for disk I/O read/write rate over the entire period as a percentage of the maximum disk I/O rate. Default: %(default)s',
        dest='WARN',
        type=int,
        default=DEFAULT_WARN,
    )

    return parser.parse_args()


def main():    
    """The main function. Hier spielt die Musik.
    """

    # parse the command line, exit with UNKNOWN if it fails
    try:
        args = parse_args()
    except SystemExit:
        sys.exit(STATE_UNKNOWN)

    conn = lib.base3.coe(lib.db_sqlite3.connect(filename='disk-io.db'))

    # create the perfdata table
    definition = '''
            name                TEXT NOT NULL,
            busy_time           INT NOT NULL, 
            read_bytes          INT NOT NULL,
            read_merged_count   INT NOT NULL,
            read_time           INT NOT NULL,
            write_bytes         INT NOT NULL,
            write_merged_count  INT NOT NULL,
            write_time          INT NOT NULL,
            timestamp           INT NOT NULL
        '''
    lib.base3.coe(lib.db_sqlite3.create_table(conn, definition, drop_table_first=False))
    lib.base3.coe(lib.db_sqlite3.create_index(conn, 'name'))

    # get disk data and store it to database
    try:
        disk_io_counters = psutil.disk_io_counters(perdisk=True)
    except ValueError as e:
        lib.base3.oao('psutil raised error "{}"'.format(e), STATE_UNKNOWN)

    now = lib.base3.now()

    disks = []
    for disk, values in disk_io_counters.items():
        if disk in args.IGNORE:
            continue
        # read_count and write_count are the same value for all disks, so simply ignore them
        data = {}
        data['name'] = disk
        data['busy_time'] = getattr(values, 'busy_time', 0)
        data['read_bytes'] = getattr(values, 'read_bytes', 0)
        # data['read_count'] = getattr(values, 'read_count', 0)
        data['read_merged_count'] = getattr(values, 'read_merged_count', 0)
        data['read_time'] = getattr(values, 'read_time', 0)
        data['write_bytes'] = getattr(values, 'write_bytes', 0)
        # data['write_count'] = getattr(values, 'write_count', 0)
        data['write_merged_count'] = getattr(values, 'write_merged_count', 0)
        data['write_time'] = getattr(values, 'write_time', 0)
        data['timestamp'] = now
        disks.append(disk)
        lib.base3.coe(lib.db_sqlite3.insert(conn, data))

    lib.base3.coe(lib.db_sqlite3.cut(conn, max=args.COUNT*len(disks)))
    lib.base3.coe(lib.db_sqlite3.commit(conn))

    # init some vars
    msg = 'No I/O.'
    perfdata = ''
    state = STATE_OK
    table_values = []

    max_rw = 0       # disk with the highest sum of r/w: show this on top later on
    # we warn about a "count" period/amount of time, not about the current situation above (what might be a peak only)
    for disk in sorted(disks):
        # get all historical data rows for a specific disk, newest item first
        diskdata = lib.base3.coe(lib.db_sqlite3.select(conn, 
            'SELECT * FROM perfdata WHERE name = :name ORDER BY timestamp DESC',
            {'name': disk}
        ))
        if len(diskdata) < 2:
            lib.db_sqlite3.close(conn)
            lib.base3.oao('Waiting for more data.', state)

        # calculate current rates
        timestamp_diff = diskdata[0]['timestamp'] - diskdata[1]['timestamp'] # in seconds
        if timestamp_diff == 0:
            timestamp_diff = 1
        read_bytes_per_second1 = int(float(diskdata[0]['read_bytes'] - diskdata[1]['read_bytes']) / timestamp_diff)
        write_bytes_per_second1 = int(float(diskdata[0]['write_bytes'] - diskdata[1]['write_bytes']) / timestamp_diff)
        throughput1 = read_bytes_per_second1 + write_bytes_per_second1

        # store the max. measured throughput in cache
        throughput_db = lib.cache3.get('disk-io-{}-throughput-max'.format(disk))
        if throughput_db == False:
            # unknown disk, no value
            throughput_max = 10 * 1024 * 1024      # Disk should be capable of 10 MB/sec
            lib.cache3.set('disk-io-{}-throughput-max'.format(disk), throughput_max)
        elif throughput1 > int(throughput_db):
            throughput_max = throughput1
            lib.cache3.set('disk-io-{}-throughput-max'.format(disk), throughput_max)
        else:
            throughput_max = int(throughput_db)

        # perfdata
        perfdata += lib.base3.get_perfdata('{}_busy_time'.format(disk), diskdata[0]['busy_time'], 'c', None, None, 0, None)
        perfdata += lib.base3.get_perfdata('{}_read_bytes'.format(disk), diskdata[0]['read_bytes'], 'c', None, None, 0, None)
        perfdata += lib.base3.get_perfdata('{}_read_merged_count'.format(disk), diskdata[0]['read_merged_count'], 'c', None, None, 0, None)
        perfdata += lib.base3.get_perfdata('{}_read_time'.format(disk), diskdata[0]['read_time'], 'c', None, None, 0, None)
        perfdata += lib.base3.get_perfdata('{}_write_bytes'.format(disk), diskdata[0]['write_bytes'], 'c', None, None, 0, None)
        perfdata += lib.base3.get_perfdata('{}_write_merged_count'.format(disk), diskdata[0]['write_merged_count'], 'c', None, None, 0, None)
        perfdata += lib.base3.get_perfdata('{}_write_time'.format(disk), diskdata[0]['write_time'], 'c', None, None, 0, None)

        perfdata += lib.base3.get_perfdata('{}_read_bytes_per_second'.format(disk), read_bytes_per_second1, 'B', None, None, 0, throughput_max)
        perfdata += lib.base3.get_perfdata('{}_write_bytes_per_second'.format(disk), write_bytes_per_second1, 'B', None, None, 0, throughput_max)

        if throughput1 > max_rw:
            msg = '{}: {}/s read, {}/s write (current)'.format(
                disk,
                lib.base3.bytes2human(read_bytes_per_second1),
                lib.base3.bytes2human(write_bytes_per_second1),
                )
            max_rw = read_bytes_per_second1 + write_bytes_per_second1

        # calculate read/write rate over the entire period 
        if len(diskdata) != args.COUNT:
            # not enough data yet
            continue
        timestamp_diff = diskdata[0]['timestamp'] - diskdata[args.COUNT - 1]['timestamp']            # in seconds
        if timestamp_diff == 0:
            timestamp_diff = 1
        read_bytes_per_second15 = float((diskdata[0]['read_bytes'] - diskdata[args.COUNT - 1]['read_bytes']) / timestamp_diff)
        write_bytes_per_second15 = float((diskdata[0]['write_bytes'] - diskdata[args.COUNT - 1]['write_bytes']) / timestamp_diff)
        throughput15 = read_bytes_per_second15 + write_bytes_per_second15   # let's just call it like in cpu-usage

        # get state based on max measured I/O values
        disk_state = lib.base3.get_state(throughput15, throughput_max * args.WARN / 100, throughput_max * args.CRIT / 100)
        state = lib.base3.get_worst(disk_state, state)

        if throughput15:
            table_values.append({
                'name': disk,
                'r1': lib.base3.bytes2human(read_bytes_per_second1),
                'w1': lib.base3.bytes2human(write_bytes_per_second1),
                'r15': lib.base3.bytes2human(read_bytes_per_second15),
                'w15': lib.base3.bytes2human(write_bytes_per_second15),
                't15': lib.base3.bytes2human(throughput15),
                'max': lib.base3.bytes2human(throughput_max),
                'state': lib.base3.state2str(disk_state, empty_ok=False),
                })

    lib.db_sqlite3.close(conn)

    msg = msg + '\n\n'
    if len(table_values) > 0:
        msg += lib.base3.get_table(
            table_values,
            ['name', 'max', 'r1', 'w1', 'r15', 'w15', 't15', 'state'],
            header=['Disk', 'RWmax/s', 'R1/s', 'W1/s', 'R{}/s'.format(args.COUNT), 'W{}/s'.format(args.COUNT), 'RW{}/s'.format(args.COUNT), 'State'],
            )

    lib.base3.oao(msg, state, perfdata, always_ok=args.ALWAYS_OK)


if __name__ == '__main__':
    try:
        main()
    except Exception as e:
        print_exc()
        exit(STATE_UNKNOWN)
